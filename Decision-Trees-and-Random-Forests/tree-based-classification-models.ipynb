{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://rhyme.com/assets/img/logo-dark.png\" align=center></img>\n",
    "<h2 align=\"center\">Predict Employee Churn with Decision Trees and Random Forests</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "plt.style.use(\"ggplot\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Exploratory Data Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Encode Categorical Features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Visualize Class Imbalance\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.target import ClassBalance\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Create Training and Test Sets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 & 7: Build an Interactive Decision Tree Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning: \n",
    "- The inputs are random variables $X = X_1, ..., X_p$;\n",
    "- The output is a random variable $Y.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data is a finite set $$\\mathbb{L}=\\{(x_i,y_i)|i=0, ..., N-1\\}$$\n",
    "where $x_i \\in X = X_1 \\times ... \\times X_p$ and $y_i \\in y$ are randomly drawn from $P_{X,Y}.$\n",
    "\n",
    "E.g., $(x_i,y_i)=((\\text{salary = low, department = sales, ...}),\\text{quit = 1})$\n",
    "\n",
    "- The goal is to find a model $\\varphi_\\mathbb{L}: X \\mapsto y$ minimizing $$\\text{Err}(\\varphi_\\mathbb{L}) = \\mathbb{E}_{X,Y}\\{L(Y, \\varphi_\\mathbb{L}(X))\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About:\n",
    " \n",
    " - Decision trees are non-parametric models which can model arbitrarily complex relations between inputs and outputs, without any a priori assumption\n",
    " \n",
    "- Decision trees handle numeric and categorical variables\n",
    "\n",
    "- They implement feature selection, making them robust to noisy features (to an extent)\n",
    "\n",
    "- Robust to outliers or errors in labels\n",
    "\n",
    "- Easily interpretable by even non-ML practioners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision trees: partitioning the feature space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![partition](assets/images/partition-feature-space.png)\n",
    "\n",
    "- Decision trees generally have low bias but have high variance.\n",
    "- We will solve the high variance problem in Task 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz # display the tree within a Jupyter notebook\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from ipywidgets import interactive, IntSlider, FloatSlider, interact\n",
    "import ipywidgets\n",
    "from IPython.display import Image\n",
    "from subprocess import call\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Build an Interactive Random Forest Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although randomization increases bias, it is possible to get a reduction in variance of the ensemble. Random forests are one of the most robust machine learning algorithms for a variety of problems.\n",
    "\n",
    "- Randomization and averaging lead to a reduction in variance and improve accuracy\n",
    "- The implementations are parallelizable\n",
    "- Memory consumption and training time can be reduced by bootstrapping\n",
    "- Sampling features and not solely sampling examples is crucial to improving accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def plot_tree_rf(crit=,\n",
    "                 bootstrap=,\n",
    "                 depth=IntSlider(min=,max=,value=, continuous_update=False),\n",
    "                 forests=IntSlider(min=,max=,value=,continuous_update=False),\n",
    "                 min_split=IntSlider(min=,max=,value=, continuous_update=False),\n",
    "                 min_leaf=IntSlider(min=,max=,value=, continuous_update=False)):\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Feature Importance and Evaluation Metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import FeatureImportances\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Type code below this line ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Code ##\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "visualizer = ROCAUC(rf, classes=[\"stayed\", \"quit\"])\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Code ##\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
    "            splitter='best')\n",
    "\n",
    "visualizer = ROCAUC(dt, classes=[\"stayed\", \"quit\"])\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.poof();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Optional: Comparison with Logistic Regression Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logit = LogisticRegressionCV(random_state=1, n_jobs=-1,max_iter=500,\n",
    "                             cv=10)\n",
    "\n",
    "lr = logit.fit(X_train, y_train)\n",
    "\n",
    "print('Logistic Regression Accuracy: {:.3f}'.format(accuracy_score(y_test, lr.predict(X_test))))\n",
    "\n",
    "visualizer = ROCAUC(lr, classes=[\"stayed\", \"quit\"])\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
